---
title: Two-Dimension LDA
author: John Lee
date: '2019-02-04'
slug: two-dimension-lda
categories:
  - machine learning
tags:
  - regression
  - classification
subtitle: ''
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>
<link href="/rmarkdown-libs/lightable/lightable.css" rel="stylesheet" />


<p>LDA, Linear Discriminant Analysis, is a classification method and a dimension reducion technique. I’ll focus more on classification. LDA calculates a <em>linear discriminant function</em> (which arises from assuming Gaussian distribution) for each class, and chooses a class that maximizes such function. The linear <em>discriminant function</em> therefore dictates a linear decision boundary for choosing a class. The decision boundary should be linear in the feature space. Discriminant analysis itself isn’t inherently linear. LDA is just a special case of discriminant analysis that arises from the assumption that all the classes share the same covariance matrix.</p>
<p>Discriminant function of class <span class="math inline">\(k\)</span>:
<span class="math display">\[\delta(x) = x^T \Sigma^{-1}\mu_k-\frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + log(\pi_k)\]</span>
where</p>
<ul>
<li><p><span class="math inline">\(\mu_k\)</span> = mean for class k</p></li>
<li><p><span class="math inline">\(\Sigma\)</span> = pooled sample mean</p></li>
<li><p><span class="math inline">\(\pi_k\)</span> = prior for class k.</p></li>
</ul>
<p>Usually these parameters are unkown, and they are derived from the sample.</p>
<p>To predict the class for new data points, calculate the discriminant function for each class</p>
<p>Again, this result arises with the assumptions that:</p>
<ul>
<li>each class is from a normal distribution with class-specific mean <span class="math inline">\((\mu_k)\)</span></li>
<li>the normal distributions share a common variance <span class="math inline">\((\Sigma)\)</span></li>
</ul>
<p>Example with a 2-class case.</p>
<p>First, create training samples &amp; test samples</p>
<pre class="r"><code>library(tidyverse)
library(mixtools)
library(MASS)
library(latex2exp)
library(kableExtra)
library(knitr)
library(formattable)

set.seed(285)
S &lt;- matrix(c(1,0.5,0.5,1), 2); n_each &lt;- 50 # set equal covariance for all 
true_mu_a &lt;- c(1,1); true_mu_b &lt;- c(3,3)

#training samples
a &lt;- mvrnorm(n_each, mu = true_mu_a, Sigma = S) # bivariate normal distribution with mean = (1,1)
b &lt;- mvrnorm(n_each, mu = true_mu_b, Sigma = S) # bivariate normal distribution with mean = (3,3)
mydf &lt;- data.frame(x1 = c(a[,1], b[,1]), x2 = c(a[,2], b[,2]), cl = rep(c(&#39;A&#39;,&#39;B&#39;),each = n_each))
print(head(mydf))</code></pre>
<pre><code>##           x1        x2 cl
## 1  1.2884039  1.695735  A
## 2  0.6343596  1.303904  A
## 3  3.0019974  1.067433  A
## 4 -1.4700693 -1.066326  A
## 5  1.0066906  1.972617  A
## 6  1.3897566  1.871020  A</code></pre>
<pre class="r"><code>#create test points
test_n_each &lt;- 40
a_test &lt;- mvrnorm(test_n_each, mu = true_mu_a, Sigma = S)
b_test &lt;- mvrnorm(test_n_each, mu = true_mu_b, Sigma = S)
mytest &lt;- data.frame(&quot;x1&quot; = c(a_test[,1], b_test[,1]), &quot;x2&quot; = c(a_test[,2], b_test[,2]))
true_class &lt;- rep(c(&quot;A&quot;, &quot;B&quot;), each = test_n_each)</code></pre>
<p>Distribution of the data:</p>
<pre class="r"><code>plot(mydf[,1], mydf[,2], col = factor(mydf[,3]), pch = 1, main = &quot;Data distribution&quot;, xlab = &quot;x1&quot;, ylab = &quot;x2&quot;)</code></pre>
<p><img src="/post/2019-02-04-two-dimension-lda_files/figure-html/plt_data-1.png" width="672" /></p>
<p>Assuming that we don’t know the true <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span>, estimate them with the sample mean and sample covariance matrix.</p>
<pre class="r"><code>mu1 &lt;- apply(mydf[mydf$cl == &quot;A&quot;,c(1,2)], 2, mean) # sample mean for class A
mu2 &lt;- apply(mydf[mydf$cl == &quot;B&quot;, c(1,2)], 2, mean) # sample mean for class B
centered &lt;- as.matrix(
  mydf[,c(1,2)] - rbind(matrix(rep(mu1, n_each), ncol = 2, byrow = TRUE),
                        matrix(rep(mu2, n_each), ncol = 2, byrow = TRUE)))
varcov &lt;- t(centered) %*% centered / (nrow(centered) - 2) # pooled variace-covariance matrix
varcov_inv &lt;- solve(varcov)</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:kabletable">Table 1: </span>sample means
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
<span class="math inline">\(\hat{\mu}_A\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\hat{\mu}_B\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
x1
</td>
<td style="text-align:center;">
0.9654044
</td>
<td style="text-align:center;">
2.951309
</td>
</tr>
<tr>
<td style="text-align:left;">
x2
</td>
<td style="text-align:center;">
0.9193072
</td>
<td style="text-align:center;">
2.998684
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:kabletable">Table 1: </span>sample variance-covariance matrix inverse
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
x1
</th>
<th style="text-align:center;">
x2
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
x1
</td>
<td style="text-align:center;">
1.1477071
</td>
<td style="text-align:center;">
-0.5516819
</td>
</tr>
<tr>
<td style="text-align:left;">
x2
</td>
<td style="text-align:center;">
-0.5516819
</td>
<td style="text-align:center;">
1.3686371
</td>
</tr>
</tbody>
</table>
<p>The following functions use the discriminant function to calculate the scores.</p>
<pre class="r"><code>#used to calculate the discriminant functions
calc_score &lt;- function(x, mu, varcov_inv, prop){
  as.numeric((x %*% varcov_inv %*% mu) - 0.5 * (mu %*% varcov_inv %*%  mu) + log(prop))
}
calc_score_A &lt;- function(x){
  calc_score(x, mu1, varcov_inv, 0.5)
}
calc_score_B &lt;- function(x){
  calc_score(x, mu2, varcov_inv, 0.5)
}</code></pre>
<p>Now that I have the sample mean, sample covariance matrix, and a way to calculate and compare the scores, I can make predictions.</p>
<pre class="r"><code>test_scores &lt;- data.frame(&quot;A_score&quot; = apply(mytest, MARGIN = 1, calc_score_A),
                          &quot;B_score&quot; = apply(mytest, MARGIN = 1, calc_score_B)) %&gt;%
  mutate(&quot;Prediction&quot; = ifelse(A_score &gt; B_score, &quot;A&quot;, &quot;B&quot;)) 
test_scores %&gt;%
        mutate(
          A_score = ifelse(
            A_score &gt; B_score, 
            cell_spec(round(A_score, 4), format = &quot;html&quot;, bold = TRUE),
            round(A_score, 4)),
          B_score = ifelse(
            B_score &gt; A_score,
            cell_spec(round(B_score, 4), format = &quot;html&quot;, bold = TRUE),
            round(B_score, 4)
          )
        ) %&gt;%
  kable(&#39;html&#39;, escape = FALSE) %&gt;%
  kable_styling(full_width = FALSE) %&gt;%
  scroll_box(height = &quot;300px&quot;)</code></pre>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; ">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
A_score
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
B_score
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Prediction
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.1759</span>
</td>
<td style="text-align:left;">
-3.278
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.3776</span>
</td>
<td style="text-align:left;">
-4.0634
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.107</span>
</td>
<td style="text-align:left;">
-3.0551
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.4823</span>
</td>
<td style="text-align:left;">
-1.1914
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.5195</span>
</td>
<td style="text-align:left;">
-4.2361
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-1.3337</span>
</td>
<td style="text-align:left;">
-7.0005
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">1.1516</span>
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.9352</span>
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">1.0608</span>
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.6911</span>
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-1.6188</span>
</td>
<td style="text-align:left;">
-7.8291
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-1.5134</span>
</td>
<td style="text-align:left;">
-7.6937
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.5681</span>
</td>
<td style="text-align:left;">
-1.2204
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.0126</span>
</td>
<td style="text-align:left;">
-2.6787
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.5729</span>
</td>
<td style="text-align:left;">
-0.9481
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.3874</span>
</td>
<td style="text-align:left;">
-3.5652
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.4229</span>
</td>
<td style="text-align:left;">
-4.3903
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.3493</span>
</td>
<td style="text-align:left;">
-1.5217
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
1.7273
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">2.5746</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-1.0234</span>
</td>
<td style="text-align:left;">
-6.0853
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-1.9975</span>
</td>
<td style="text-align:left;">
-9.0358
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.2693</span>
</td>
<td style="text-align:left;">
-3.9278
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.8209</span>
</td>
<td style="text-align:left;">
-0.5283
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.3686</span>
</td>
<td style="text-align:left;">
-1.6875
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
2.367
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">4.8856</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-1.3572</span>
</td>
<td style="text-align:left;">
-7.0641
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.734</span>
</td>
<td style="text-align:left;">
-5.1947
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.2281</span>
</td>
<td style="text-align:left;">
-3.74
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.3025</span>
</td>
<td style="text-align:left;">
-1.7457
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.1377</span>
</td>
<td style="text-align:left;">
-3.3154
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.154</span>
</td>
<td style="text-align:left;">
-2.0848
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.6786</span>
</td>
<td style="text-align:left;">
-0.4303
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.4324</span>
</td>
<td style="text-align:left;">
-1.6249
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.4964</span>
</td>
<td style="text-align:left;">
-1.2815
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-2.5051</span>
</td>
<td style="text-align:left;">
-10.7099
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.6792</span>
</td>
<td style="text-align:left;">
-0.3356
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.3274</span>
</td>
<td style="text-align:left;">
-3.7487
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.5677</span>
</td>
<td style="text-align:left;">
-4.8283
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.2977</span>
</td>
<td style="text-align:left;">
-3.5145
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.2623</span>
</td>
<td style="text-align:left;">
-3.7453
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">-0.0615</span>
</td>
<td style="text-align:left;">
-3.0913
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
1.8722
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.2393</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
3.4055
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">8.0866</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
4.3429
</td>
<td style="text-align:left;">
11.0935
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.922
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.1492</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
3.4832
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">8.5813</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
3.0456
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">6.7597</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
3.0459
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">6.9929</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
3.1109
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">7.3301</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.9522
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.3569</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
2.4712
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">5.2453</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">1.1155</span>
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.6139</span>
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
1.6235
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">2.4427</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
3.8512
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">9.3066</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
4.3328
</td>
<td style="text-align:left;">
10.9274
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.5177</span>
</td>
<td style="text-align:left;">
-1.3228
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
1.9686
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.2308</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.8329
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.0792</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.7742</span>
</td>
<td style="text-align:left;">
-0.1188
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
2.9128
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">6.5723</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.5093
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">1.7485</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
2.3112
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">4.6208</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.8433
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.0966</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
2.605
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">5.5216</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
2.1003
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.7596</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">1.2751</span>
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">1.1232</span>
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
1.8186
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.0485</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
2.9834
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">6.5644</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
4.964
</td>
<td style="text-align:left;">
12.9167
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
2.7923
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">6.0654</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.9884
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.6019</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">0.7061</span>
</td>
<td style="text-align:left;">
-0.82
</td>
<td style="text-align:left;">
A
</td>
</tr>
<tr>
<td style="text-align:left;">
2.7743
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">6.0155</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.8871
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">3.5962</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.4034
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">1.6698</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
4.9516
</td>
<td style="text-align:left;">
12.9317
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.3665
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">1.4068</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
4.2016
</td>
<td style="text-align:left;">
10.6066
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
1.5156
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">2.0366</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
2.8598
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">6.2117</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
2.535
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">5.3056</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
<tr>
<td style="text-align:left;">
3.6067
</td>
<td style="text-align:left;">
<span style=" font-weight: bold;    ">8.3908</span>
</td>
<td style="text-align:left;">
B
</td>
</tr>
</tbody>
</table>
</div>
<p>You can see that the classification is based on whichever score is higher</p>
<p>Compare the results with R’s built in LDA function.</p>
<pre class="r"><code>myLDA &lt;- lda(cl ~ ., data = mydf) # built in LDA
mypred &lt;- predict(myLDA, mytest)

all(test_scores$Prediction == mypred$class)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>I’m interested in seeing what the decision boundary looks like. It’s simple. Since the classification is based on discriminant function, I just have to find out for which values of <code>x1</code> and <code>x2</code> the scores for both classes are equal.</p>
<p>i.e.</p>
<p><span class="math inline">\(\delta_A(x) - \delta_B(x) = x^T \Sigma^{-1}\mu_A-\frac{1}{2}\mu_A^T\Sigma^{-1}\mu_A + log(\pi_A) - x^T \Sigma^{-1}\mu_B+\frac{1}{2}\mu_B^T\Sigma^{-1}\mu_B - log(\pi_B) \\ = x^T\Sigma^{-1}(\mu_A-\mu_B) + \big(-\frac{1}{2}\mu_A^T\Sigma^{-1}\mu_A+\frac{1}{2}\mu_B^T\Sigma^{-1}\mu_B\big)\)</span></p>
<pre class="r"><code>coeff_tmp &lt;- varcov_inv %*% (mu1 - mu2)
intercept_tmp &lt;- - 0.5 * (mu1 %*% varcov_inv %*% mu1) + 0.5 * (mu2 %*% varcov_inv %*% mu2)

slope &lt;- coeff_tmp[1] / -coeff_tmp[2]
intercept &lt;- intercept_tmp / -coeff_tmp[2]

message(paste0(&quot;slope: &quot;, slope, &quot;, intercept: &quot;, intercept))</code></pre>
<pre><code>## slope: -0.646784109561366, intercept: 3.22562929419369</code></pre>
<pre class="r"><code>plot(mydf[,1], mydf[,2], col = factor(mydf[,3]), pch = 1, main = &quot;Linear Boundary with Training Points&quot;, xlab = &quot;x1&quot;, ylab = &quot;x2&quot;)
abline(b = slope, a = intercept)</code></pre>
<p><img src="/post/2019-02-04-two-dimension-lda_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>plot(mytest[,1], mytest[,2], col = factor(test_scores[,3]), pch = 1, main = &quot;Linear Boundary with Test Points&quot;, xlab = &quot;x1&quot;, ylab = &quot;x2&quot;)
abline(b = slope, a = intercept)</code></pre>
<p><img src="/post/2019-02-04-two-dimension-lda_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<p>The line doesn’t perfectly separate the training data points because they are not linearly separable without any transformation. But you can see that the class predictions are based on which side of the line the points lie on.</p>
<p>An interesting thing to point out is the relation between LDA and linear discriminant analysis. If I set each class as 1 and -1 (A and B resp.), run linear regression with the intercept, and classify based on size relative to 0, the predictions are the same!</p>
<pre class="r"><code>mydf &lt;- mydf %&gt;% mutate(y = ifelse(cl == &quot;A&quot;, 1, -1))

mylm &lt;- lm(y ~ x1 + x2, mydf)
classes &lt;- ifelse(predict(mylm, mytest) &gt; 0, &quot;A&quot;, &quot;B&quot;)
all(classes == test_scores$Prediction)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>I’ve wanted to try implementing my own vanilla version of the LDA, and visualize the results. It definitely helps understanding the problem in a simple case (like running LDA in the two dimensional case), and then generalize the results to a more complex case.</p>
